---
name: Download API Endpoints
status: open
created: 2026-02-25T02:28:43Z
updated: 2026-02-25T02:41:06Z
github: https://github.com/B30780/AOI_inference_agent/issues/7
depends_on: [2, 4, 5]
parallel: true
conflicts_with: []
---

# Task: Download API Endpoints

## Description
Implement download endpoints that allow users to retrieve individual images (input, combined, mask, overlay), analysis JSON files, and batch results as ZIP archives. Include proper content-type headers and file streaming.

## Acceptance Criteria
- [ ] GET /download/image/{img_unique_id}/{type} endpoint for downloading specific images
- [ ] GET /download/json/{img_unique_id} endpoint for downloading analysis JSON
- [ ] GET /download/batch/{batch_id} endpoint for downloading batch results as ZIP
- [ ] Proper content-type headers (image/png, application/json, application/zip)
- [ ] File streaming for efficient large file downloads
- [ ] File existence validation before download
- [ ] 404 errors for non-existent files
- [ ] Download filenames include meaningful information
- [ ] API tests for all download scenarios

## Technical Details

**Download Endpoints (app/api/download.py):**

```python
from fastapi import APIRouter, Depends, HTTPException, Path
from fastapi.responses import FileResponse, StreamingResponse
from sqlalchemy.orm import Session
from pathlib import Path as FilePath
from app.services.db_service import DBService
from app.services.storage import StorageService
import json

router = APIRouter()

@router.get("/download/image/{img_unique_id}/{image_type}")
async def download_image(
    img_unique_id: str = Path(..., description="Image unique ID"),
    image_type: str = Path(..., regex="^(input|combined|mask|overlay)$"),
    db: Session = Depends(get_db)
):
    """
    Download specific image type for an image.
    
    Args:
        img_unique_id: Unique identifier for the image
        image_type: Type of image (input, combined, mask, overlay)
    """
    db_service = DBService(db)
    image = db_service.get_image_by_id(img_unique_id)
    
    if not image:
        raise HTTPException(status_code=404, detail="Image not found")
    
    # Get file path based on type
    if image_type == "input":
        file_path = image.input_image_path
    elif image_type == "combined":
        file_path = image.result_image_1_path
    elif image_type == "mask":
        file_path = image.result_image_2_path
    elif image_type == "overlay":
        file_path = image.result_image_3_path
    
    if not file_path or not FilePath(file_path).exists():
        raise HTTPException(
            status_code=404, 
            detail=f"{image_type} image not found"
        )
    
    # Determine filename for download
    filename = f"{img_unique_id}_{image_type}.png"
    
    return FileResponse(
        path=file_path,
        media_type="image/png",
        filename=filename
    )

@router.get("/download/json/{img_unique_id}")
async def download_json(
    img_unique_id: str,
    db: Session = Depends(get_db)
):
    """Download analysis JSON for an image."""
    db_service = DBService(db)
    
    # Get image data
    image = db_service.get_image_by_id(img_unique_id)
    if not image:
        raise HTTPException(status_code=404, detail="Image not found")
    
    # Get classes and regions
    classes = db_service.get_classes_by_image(img_unique_id)
    regions = db_service.get_regions_by_image(img_unique_id)
    
    # Build JSON response matching the analysis format
    analysis_data = {
        "image_shape": {
            "height": image.image_height,
            "width": image.image_width
        },
        "classes": {},
        "performance": {
            "processing_time_seconds": image.processing_time_seconds,
            "timestamp": image.timestamp.isoformat()
        }
    }
    
    # Group regions by class
    for cls in classes:
        cls_regions = [r for r in regions if r.class_unique_id == cls.class_unique_id]
        
        analysis_data["classes"][cls.class_name] = {
            "class_id": cls.class_id,
            "total_regions": cls.total_regions,
            "total_area_pixels": cls.total_area_pixels,
            "regions": [
                {
                    "region_id": r.region_id,
                    "centroid": {"x": r.centroid_x, "y": r.centroid_y},
                    "bounding_box": {
                        "x": r.bbox_x,
                        "y": r.bbox_y,
                        "width": r.bbox_width,
                        "height": r.bbox_height
                    },
                    "area_pixels": r.area_pixels,
                    "perimeter": r.perimeter,
                    "major_axis": r.major_axis,
                    "minor_axis": r.minor_axis,
                    "circularity": r.circularity,
                    "aspect_ratio": r.aspect_ratio
                }
                for r in cls_regions
            ]
        }
    
    # Return as downloadable JSON
    json_str = json.dumps(analysis_data, indent=2)
    
    return StreamingResponse(
        iter([json_str]),
        media_type="application/json",
        headers={
            "Content-Disposition": f"attachment; filename={img_unique_id}_analysis.json"
        }
    )

@router.get("/download/batch/{batch_id}")
async def download_batch(
    batch_id: str,
    db: Session = Depends(get_db)
):
    """Download batch results as ZIP archive."""
    storage = StorageService()
    
    try:
        zip_path = await storage.generate_batch_zip(batch_id)
        
        if not FilePath(zip_path).exists():
            raise HTTPException(
                status_code=404, 
                detail="Batch results not found"
            )
        
        return FileResponse(
            path=zip_path,
            media_type="application/zip",
            filename=f"batch_{batch_id}_results.zip"
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=500, 
            detail=f"Failed to generate batch ZIP: {str(e)}"
        )
```

**Storage Service Updates:**

Complete the `generate_batch_zip` method in StorageService:

```python
async def generate_batch_zip(self, batch_id: str) -> str:
    """Create ZIP archive of batch results."""
    import zipfile
    
    # Find batch directory
    batch_dir = None
    for date_dir in self.result_dir.iterdir():
        if date_dir.is_dir():
            potential_batch = date_dir / f"batch_{batch_id}"
            if potential_batch.exists():
                batch_dir = potential_batch
                break
    
    if not batch_dir:
        raise FileNotFoundError(f"Batch {batch_id} not found")
    
    # Create ZIP file
    zip_path = batch_dir.parent / f"batch_{batch_id}.zip"
    
    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for file_path in batch_dir.rglob('*'):
            if file_path.is_file():
                arcname = file_path.relative_to(self.result_dir)
                zipf.write(file_path, arcname)
    
    return str(zip_path)
```

## Dependencies
- [ ] Task 2 completed (database models)
- [ ] Task 4 completed (storage service)
- [ ] Task 5 completed (upload creates data to download)

## Effort Estimate
- Size: M
- Hours: 6-8 hours
- Parallel: true (can be developed alongside query endpoints)

## Definition of Done
- [ ] All download endpoints implemented
- [ ] File streaming working efficiently
- [ ] Content-type headers correct
- [ ] ZIP generation functional
- [ ] 404 handling for missing files
- [ ] API tests written with >80% coverage
- [ ] Downloaded files verified correct
- [ ] Code reviewed

